# -*- coding: utf-8 -*-
"""GANS_and_PCA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BecL5gdgLNpKUpBZRUaaKJPQ5QYerz3n
"""

import tensorflow as tf

tf.__version__

import matplotlib.pyplot as plt
import numpy as np
import os
import PIL
from tensorflow.keras import layers
import time

from IPython import display

(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()
print(train_images.shape)
print(train_labels.shape)
#train_images = train_images[:20000]

train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')
# Normalize the images to [-1, 1]
train_images = (train_images - 127.5) / 127.5

BUFFER_SIZE = 10000
BATCH_SIZE = 256

# Batch and shuffle the data
train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)
print(type(train_dataset))
print(train_dataset)

def make_generator_model():
  # Making a sequential layer of neural networks
  model = tf.keras.Sequential()
  # Creating a dense layer of fully connected neural network
  model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))
  # Applying batch normalization step to normalize the activations.
  model.add(layers.BatchNormalization())
  # Adding relu activation layer
  model.add(layers.LeakyReLU())

  model.add(layers.Reshape((7, 7, 256)))

  # Add the convolutional 2d layer
  model.add(layers.Conv2DTranspose(128, (5,5), strides=(1,1), padding="same", use_bias=False))
  # Applying batch normalization step to normalize the activations
  model.add(layers.BatchNormalization())
  # Adding relu activation layer
  model.add(layers.LeakyReLU())

  # Add the convolutional 2d layer
  model.add(layers.Conv2DTranspose(64, (5,5), strides=(2,2), padding="same", use_bias=False))
  # Applying batch normalization step to normalize the activations
  model.add(layers.BatchNormalization())
  # Adding relu activation layer
  model.add(layers.LeakyReLU())

  # Add the final convolutional 2d transpose layer
  model.add(layers.Conv2DTranspose(1, (5,5), strides=(2,2), padding="same", use_bias=False, activation="tanh"))

  return model

# Generating an image from untrained generator
generator = make_generator_model()
noise = tf.random.normal([1, 100])
generated_image = generator(noise, training=False)
plt.imshow(generated_image[0], cmap='gray')

def make_discriminator_model():
  # Making a sequential layer of neural networks
  model = tf.keras.Sequential()
  # Adding convolutional 2d layer
  model.add(layers.Conv2D(64, (5,5), strides=(2,2), padding="same", input_shape=[28, 28, 1]))

  # Adding the Relu activation function
  model.add(layers.LeakyReLU())
  # Dropout randomly sets 0.3 fraction of input units to 0
  model.add(layers.Dropout(0.3))

  # Add the convolutional 2d layer
  model.add(layers.Conv2D(128, (5,5), strides=(2,2), padding="same"))
  # Add the relu activation function
  model.add(layers.LeakyReLU())
  model.add(layers.Dropout(0.3))

  model.add(layers.Flatten())
  model.add(layers.Dense(1))

  return model

discriminator = make_discriminator_model()
decision = discriminator(generated_image)
print(decision)

# This method returns a helper function to compute cross entropy loss
cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)

def discriminator_loss(real_output, fake_output):
  real_loss = cross_entropy(tf.ones_like(real_output), real_output)
  fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)
  total_loss = real_loss + fake_loss
  return total_loss

def generator_loss(fake_output):
  # Here compare the discriminators decisions on the generated images to an array of 1s
  return cross_entropy(tf.ones_like(fake_output), fake_output)

generator_optimizer = tf.keras.optimizers.Adam(1e-4)
discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)

EPOCHS = 50
noise_dim = 100
num_examples_to_generate = 15000

# You will reuse this seed overtime
seed = tf.random.normal([num_examples_to_generate, noise_dim])

# Training starts with generator receiving a random seed as input. This seed
# is used to produce an image. The discriminator is then used to classify real
# images (drawn from the dataset) and fake images(produced by the generator)
# The loss is calculated for each of these models, and the gradients are used to update  the
# generator and the discriminator

# Notice the use of `tf.function`
# This annotation causes the function to be "compiled".
@tf.function
def train_step(images):
  noise = tf.random.normal([BATCH_SIZE, noise_dim])

  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:
    generated_images = generator(noise, training=True)

    real_output = discriminator(images, training=True)
    fake_output = discriminator(generated_images, training=True)

    gen_loss = generator_loss(fake_output)
    disc_loss = discriminator_loss(real_output, fake_output)

  gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)
  gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)

  generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))
  discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))

def train(dataset, epochs):
  for epoch in range(epochs):
    for image_batch in dataset:
      train_step(image_batch)

   # generate_and_save_images(generator, epoch + 1, seed)

  generate_and_save_images(generator, epochs, seed)

def generate_and_save_images(model, epoch, test_input):
  predictions = model(test_input, training=False)
  print("The size of prediction is: ", predictions.shape)
  pred = predictions
  # fig = plt.figure(figsize=(4,4))
  # for i in range(predictions.shape[0]):
  #   plt.subplot(10, 10, i+1)
  #   plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')
  #   plt.axis('off')

  # plt.show()

train(train_dataset, EPOCHS)

predictions = generator(seed, training=False)
disc_pred = discriminator(predictions, training=False)

print(predictions.shape)

predictions = tf.reshape(predictions, shape=(-1, 784))
print(predictions.shape)

# 2D Visualization using PCA

from sklearn.preprocessing import StandardScaler
standardized_data = StandardScaler().fit_transform(predictions)
print(standardized_data.shape)

sample_data = standardized_data

from sklearn.decomposition import PCA
pca = PCA(n_components = 2)
obj = pca.fit_transform(sample_data)
print(obj.shape)

print(pca.components_)

print(sum(pca.explained_variance_ratio_))
print(pca.explained_variance_ratio_)

var_ratio = []
nums = [10, 50, 100, 200, 300, 400, 500]
for num in nums:
  pca = PCA(n_components=num)
  pca.fit(sample_data).transform(sample_data)
  var_ratio.append(np.sum(pca.explained_variance_ratio_))

plt.figure(figsize=(4,2), dpi=150)
plt.grid()
plt.plot(nums, var_ratio, marker='o')
plt.xlabel('n_components')
plt.ylabel('Explained variance ratio')
plt.title('n_components vs Explained Variance Ratio')

plt.figure(figsize=(8, 4))
plt.scatter(predictions[:, 0], predictions[:, 1], c='blue', label='Generated Images')
plt.scatter(train_images[:, 0], train_images[:, 1], c='red', label='Real MNIST Images')
plt.title('Scatter Plot of GAN-generated and Real MNIST Images')
plt.legend()
plt.show()

